from pymongo import MongoClient
from bson.objectid import ObjectId

# Configuration for the source MongoDB
source_db_uri = "mongodb://source_username:source_password@source_host:source_port/source_db_name"
source_collection_name = "source_collection"

# Configuration for the target MongoDB
target_db_uri = "mongodb://target_username:target_password@target_host:target_port/target_db_name"
target_collection_name = "target_collection"

# Connect to the source MongoDB
source_client = MongoClient(source_db_uri)
source_db = source_client.get_default_database()  # Adjust if your db name is different
source_collection = source_db[source_collection_name]

# Connect to the target MongoDB
target_client = MongoClient(target_db_uri)
target_db = target_client.get_default_database()  # Adjust if your db name is different
target_collection = target_db[target_collection_name]

# Batch processing configuration
batch_size = 10000  # Number of documents to process in each batch
last_id = None  # Keeps track of the last document ID processed

# Function to transfer data in batches
def transfer_data_in_batches():
    global last_id
    while True:
        query = {"_id": {"$gt": ObjectId(last_id)}} if last_id else {}
        batch_data = list(source_collection.find(query).limit(batch_size))
        
        if not batch_data:
            break  # Exit the loop if no more data to transfer
        
        target_collection.insert_many(batch_data)
        last_id = batch_data[-1]["_id"]
        print(f"Transferred {len(batch_data)} documents to target collection.")

# Execute the data transfer
try:
    transfer_data_in_batches()
    print("Data transfer complete.")
except Exception as e:
    print(f"An error occurred during data transfer: {e}")
finally:
    # Close the MongoDB connections
    source_client.close()
    target_client.close()
